{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"IMDB_Dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  label\n",
       "0  One of the other reviewers has mentioned that ...  positive      1\n",
       "1  A wonderful little production. <br /><br />The...  positive      1\n",
       "2  I thought this was a wonderful way to spend ti...  positive      1\n",
       "3  Basically there's a family where a little boy ...  negative      0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"] = data[\"sentiment\"].apply(lambda x: int(x == \"positive\"))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label_str</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review label_str  label\n",
       "0  One of the other reviewers has mentioned that ...  positive      1\n",
       "1  A wonderful little production. <br /><br />The...  positive      1\n",
       "2  I thought this was a wonderful way to spend ti...  positive      1\n",
       "3  Basically there's a family where a little boy ...  negative      0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.rename(columns={\"sentiment\": \"label_str\"})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   label_str  50000 non-null  object\n",
      " 2   label      50000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3) (5000, 3) (5000, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=271)\n",
    "data_val, data_test = train_test_split(data_val, test_size=0.5, random_state=314)\n",
    "\n",
    "print(data_train.shape, data_val.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv(\"./imdb_train.csv\", index=False)\n",
    "data_val.to_csv(\"./imdb_val.csv\", index=False)\n",
    "data_test.to_csv(\"./imdb_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing, Tokenizing and Padding Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'label_str', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/emrebaloglu/Documents/RL/basic_reinforcement_learning\")\n",
    "import NLP_utils.preprocessing as nlp_processing\n",
    "\n",
    "data_path = \"/Users/emrebaloglu/Documents/RL/basic_reinforcement_learning/NLP_datasets/IMDB_reviews\"\n",
    "data = pd.read_csv(data_path + \"/imdb_train.csv\")\n",
    "print(data.columns)\n",
    "data_val = pd.read_csv(data_path + \"/imdb_val.csv\")\n",
    "data_test = pd.read_csv(data_path + \"/imdb_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Process with default tokenizer** (skip this part if you wish bert tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 115956.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_words_1:  115956\n",
      "On column ['review_tokenized'], maximum sentence length is 2388.\n",
      "max_len_1:  2388\n",
      "Vocabulary size: 122058.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_words_2:  122058\n",
      "On column ['review_tokenized'], maximum sentence length is 2388.\n",
      "Vocabulary size: 127568.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_words_2:  127568\n",
      "On column ['review_tokenized'], maximum sentence length is 2388.\n",
      "(5000, 2388)\n",
      "                                                 review label_str  label  \\\n",
      "2773  National Lampoon Class Reunion is classic come...  positive      1   \n",
      "2791  Sondra Locke stinks in this film but then she ...  negative      0   \n",
      "3114  I wouldn go so far as to not recommend this mo...  positive      1   \n",
      "2692   Gone With The Wind is one of the most overrat...  negative      0   \n",
      "774   You ve been fouled and beaten up in submission...  negative      0   \n",
      "\n",
      "                                       review_tokenized  \n",
      "2773  [3147, 8965, 9237, 16970, 5, 367, 211, 17, 34,...  \n",
      "2791  [11366, 8580, 5125, 7, 10, 17, 18, 106, 63, 11...  \n",
      "3114  [131, 605, 147, 37, 236, 14, 4, 22, 372, 10, 1...  \n",
      "2692  [4338, 539, 12, 4106, 5, 26, 3, 1, 87, 4554, 9...  \n",
      "774   [193, 138, 72, 45875, 2, 3620, 50, 7, 12686, 2...  \n",
      "(5000, 2388)\n",
      "5000 2\n",
      "(1194,)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data, tokenizer = nlp_processing.tokenize_data(data, [\"review\"], preprocess=True)\n",
    "print(\"n_words_1: \", len(tokenizer.word_index) + 1)\n",
    "data, max_len = nlp_processing.pad_tokenized_data(data, [\"review_tokenized\"])\n",
    "print(\"max_len_1: \", max_len)\n",
    "\n",
    "\n",
    "data_val, tokenizer = nlp_processing.tokenize_data(data_val, [\"review\"], preprocess=True, tokenizer=tokenizer)\n",
    "print(\"n_words_2: \", len(tokenizer.word_index) + 1)\n",
    "data_val, _ = nlp_processing.pad_tokenized_data(data_val, [\"review_tokenized\"], max_len=max_len)\n",
    "\n",
    "\n",
    "data_test, tokenizer = nlp_processing.tokenize_data(data_test, [\"review\"], preprocess=True, tokenizer=tokenizer)\n",
    "print(\"n_words_2: \", len(tokenizer.word_index) + 1)\n",
    "data_test, _ = nlp_processing.pad_tokenized_data(data_test, [\"review_tokenized\"], max_len=max_len)\n",
    "print(np.stack(data_test[\"review_tokenized\"].values).shape) \n",
    "   \n",
    "# save the processed data in pickle files\n",
    "\n",
    "nlp_processing.storeDf2Pickle(data, data_path + \"/imdb-train.pkl\")\n",
    "nlp_processing.storeDf2Pickle(data_val, data_path + \"/imdb-val.pkl\")\n",
    "nlp_processing.storeDf2Pickle(data_test, data_path + \"/imdb-test.pkl\")\n",
    "\n",
    "data_info = {\"path\": data_path, \"max_len\": max_len, \"vocab_size\": len(tokenizer.word_index) + 1}\n",
    "with open(data_path + \"/data_info.json\", \"w\") as out:\n",
    "    json.dump(data_info, out)\n",
    "\n",
    "data_test = nlp_processing.openDfFromPickle(data_path + \"/imdb-test.pkl\")\n",
    "print(data_test.sample(5))\n",
    "samples = np.stack(data_test[\"review_tokenized\"].values)\n",
    "print(samples.shape)\n",
    "ss = []\n",
    "for j in range(samples.shape[0]):\n",
    "    ss.append(np.split(samples[j], 2))\n",
    "\n",
    "print(len(ss), len(ss[0]))\n",
    "print(ss[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Process with pretrained bert tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2469\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/emrebaloglu/Documents/RL/basic_reinforcement_learning/NLP_datasets/IMDB_reviews\"\n",
    "data = pd.read_csv(data_path + \"/imdb_train.csv\")\n",
    "max_len = max(len(x.split(\" \"))-1 for x in data[\"review\"].values)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'label_str', 'label'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying bert-tokenization on review.: 100%|██████████| 40000/40000 [03:03<00:00, 218.37it/s]\n",
      "Applying bert-tokenization on review.: 100%|██████████| 5000/5000 [00:23<00:00, 214.20it/s]\n",
      "Applying bert-tokenization on review.: 100%|██████████| 5000/5000 [00:23<00:00, 214.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['review', 'label_str', 'label', 'review_bert_input_ids',\n",
      "       'review_bert_token_type_ids', 'review_bert_attention_mask'],\n",
      "      dtype='object')\n",
      "Index(['review', 'label_str', 'label', 'review_bert_input_ids',\n",
      "       'review_bert_token_type_ids', 'review_bert_attention_mask'],\n",
      "      dtype='object')\n",
      "                                              review label_str  label  \\\n",
      "0  Once again fell for it in my roots crave fun a...  negative      0   \n",
      "1  Of all the movies in the history of movies can...  negative      0   \n",
      "2  Like most other reviewers really enjoyed this ...  positive      1   \n",
      "3  What waste of time ve tried to sit through Sky...  negative      0   \n",
      "4  Not only is this very interesting exploration ...  positive      1   \n",
      "\n",
      "                               review_bert_input_ids  \\\n",
      "0  [101, 2857, 1254, 2204, 1111, 1122, 1107, 1139...   \n",
      "1  [101, 2096, 1155, 1103, 5558, 1107, 1103, 1607...   \n",
      "2  [101, 2409, 1211, 1168, 19475, 1541, 4927, 114...   \n",
      "3  [101, 1327, 5671, 1104, 1159, 1396, 1793, 1106...   \n",
      "4  [101, 1753, 1178, 1110, 1142, 1304, 5426, 1001...   \n",
      "\n",
      "                          review_bert_token_type_ids  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                          review_bert_attention_mask  \n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
      "review                        Once again fell for it in my roots crave fun a...\n",
      "label_str                                                              negative\n",
      "label                                                                         0\n",
      "review_bert_input_ids         [101, 2857, 1254, 2204, 1111, 1122, 1107, 1139...\n",
      "review_bert_token_type_ids    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
      "review_bert_attention_mask    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "Name: 0, dtype: object\n",
      "[  101  2857  1254  2204  1111  1122  1107  1139  6176   172 22116  4106\n",
      "  1105  1301  1616  5367  1273  1256  3980  1141  2431  1191  1122  4736\n",
      "  1112  1263  1112  1243  1139  4106  1301  1874  1107  1103  5495   182\n",
      "  2816  3227  1200  1122  2144  1321  1277  1573  1486  1103  2267  1104\n",
      "   139  2433  1166  1120  4613  6301  1105  1108  1912  1104  8193  1184\n",
      "  1122  1108  1164  1122  1350  1912  1104  5426  1177  1879  1106  9795\n",
      "  1122  2009  2009  1202  1579  2303  1111  1122  1753  1178  1225  1142\n",
      "  2523  1136 14414  1103 10241  1834  1111  1139  1301  1874  1105  2305\n",
      "  2008  4289  1105   183 17294  2340  1133  1108 11920  1149  1104  1713\n",
      "  1188  2523  1144  1103 24181  5114 11506  1106  1474  1122   170  3980\n",
      "  2523  1105  1122  1541  1136   182  1177  1601  1106  1280  1171  1106\n",
      "  1103  2984  1105 13498  1111  1948  1171  1272  1142  1110  1141  1104\n",
      "  1103  4054  1551  2140  1454  1103  2523  1228  9304  9304  1760  2360\n",
      "  5636  3980  1341  3840  9238  1186   182  1253  1774  1106  2482  1149\n",
      "  1184  1103 26913  1119  1108  1133  1117  1271  1108 11336  1394  2427\n",
      "  1177   182 11577  2654  1119   170 11012 20073  5497  2564  1150  7407\n",
      "  1106 14406  1234  1149  1341  3840  9238  1186 10756  1116  1119  6191\n",
      "  1103  2360  1144  2218 20646  1111  4542  1177  1119  3114  1123  3850\n",
      "  1106  1301  1154  1126  7551  7369  1187  3980  5903  1105  2993  1892\n",
      "  1106  1561  3534  1341  3840  9238  1186  1573  1123  2053  1243  7215\n",
      "  1105  4958  1152 16445  2222  1103  3850  1315  1341  3840  9238  1186\n",
      "  1573  1170  1152  4958  1106  2222  1103  3850  1614  1243  6994  1103\n",
      " 25147  1132  1842  1341  3840  9238  1186  1105  1103  3980  1110  1208\n",
      "  8965  1103  1209  1992  7209  1174  2636  1107 14884 18733 14439  5413\n",
      "  1341  3840  9238  1186  1252  2337  1104  1103  2636  1541  1322  1146\n",
      "  1217  6039  1341  3840  9238  1186  9304  9304  6502  1111  1155  1103\n",
      "  3840  9238  1186  1142  1110  3566  1141  1104  1103  4997  3761   182\n",
      "  1280  1106  3593  1133  1115  1272  1142  2523  1108  1198  9684 12533\n",
      "  1105 18110  1567  1198  3195  1292 16445  1129  5681  1150  1128  1169\n",
      "  1587  1132 17989  1116  1702  1111  1115  1992  2549  1753  1315  6866\n",
      "  1115  1152  2204  1107  1103   172 16879  1104  1103  5367  6453  2121\n",
      "  1122  1759  1105  2121  1122  2144  1107  1142  1692  1152  1541  1431\n",
      "  1138  2373  1103  5444  2279  1103  2523  1103  1440  1103  1631  1103\n",
      "  3176  1917  1164  1142  2523  1108  1198  2213  1541 18029  1115  1128\n",
      "  1198  2789  1103  2523  1191  1128  1267  1122  1120  1240  1888  2984\n",
      "  1188  3566  1180  1138  1151  1126  5426  2523  1114  1122  3400  1104\n",
      "  1472 11025  1133  1725  1225  1152  3368  1142  1900  1106  3934  1117\n",
      " 17980  1191  1119  1256  1144  1251  1188  1108  2213  2523  1198  2215\n",
      "  1283  9304  9304   102     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "[CLS] Once again fell for it in my roots crave fun and gory horror film even vampire one Even if it stupid as long as get my fun gore in the mix m happy camper it doesn take much So saw the cover of Bled over at Hollywood Video and was kind of curious what it was about it looked kind of interesting so decided to rent it Why Why do always fall for it Not only did this movie not fulfill the satisfaction needed for my gore and senseless violence and nudity but was bored out of mind This movie has the kahoonies to say it a vampire movie and it really not m so close to going back to the store and begging for money back because this is one of the rare times actually turned the movie off br br An artist meets vampire think dunno m still trying to figure out what the heck he was but his name was Reinfield so m assuming maybe he a cockroach eating guy who likes to freak people out think dunno Anyways he thinks the artist has certain flare for darkness so he gives her drug to go into an alternate fantasy where vampire exists and needs blood to become alive think dunno So her friends get excited and decide they wanna try the drug too think dunno So after they decide to try the drug things get weird the fantasies are real think dunno and the vampire is now enjoying the will big breasted girls in scandly clad clothing think dunno But couple of the girls really end up being vampires think dunno br br Sorry for all the dunno this is possibly one of the worst reviews m going to write but that because this movie was just awful boring and confusing love just seeing these wanna be actors who you can tell are waiters looking for that big break Not too smart that they fell in the clich of the horror genre sometimes it works and sometimes it doesn in this case they really should have read the script Because the movie the look the feel the acting everything about this movie was just bad really recommend that you just pass the movie if you see it at your video store This possibly could have been an interesting movie with it concept of different dimension but why did they pick this director to display his creativity if he even has any This was bad movie just stay away br br [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/emrebaloglu/Documents/RL/basic_reinforcement_learning/NLP_datasets/IMDB_reviews\"\n",
    "data = pd.read_csv(data_path + \"/imdb_train.csv\")\n",
    "print(data.columns)\n",
    "data_val = pd.read_csv(data_path + \"/imdb_val.csv\")\n",
    "data_test = pd.read_csv(data_path + \"/imdb_test.csv\")\n",
    "\n",
    "data = nlp_processing.process_df_texts(data, [\"review\"])\n",
    "data_val = nlp_processing.process_df_texts(data_val, [\"review\"])\n",
    "data_test = nlp_processing.process_df_texts(data_test, [\"review\"])\n",
    "max_len = 512\n",
    "data, tokenizer = nlp_processing.bert_tokenize_data(data, None, [\"review\"], max_len=max_len)\n",
    "data_val, tokenizer = nlp_processing.bert_tokenize_data(data_val, tokenizer, [\"review\"], max_len=max_len)\n",
    "data_test, tokenizer = nlp_processing.bert_tokenize_data(data_test, tokenizer, [\"review\"], max_len=max_len)\n",
    "\n",
    "data_info_bert = {\"path\": data_path, \"max_len\": max_len, \"vocab_size\": tokenizer.vocab_size}\n",
    "with open(data_path + \"/data_info_bert.json\", \"w\") as out:\n",
    "    json.dump(data_info_bert, out)\n",
    "\n",
    "print(data.columns)\n",
    "\n",
    "nlp_processing.storeDf2Pickle(data, data_path + \"/imdb-train-bert.pkl\")\n",
    "nlp_processing.storeDf2Pickle(data_val, data_path + \"/imdb-val-bert.pkl\")\n",
    "nlp_processing.storeDf2Pickle(data_test, data_path + \"/imdb-test-bert.pkl\")\n",
    "\n",
    "data = nlp_processing.openDfFromPickle(data_path + \"/imdb-train-bert.pkl\")\n",
    "print(data.columns)\n",
    "print(data.head())\n",
    "dd = data.iloc[0,:]\n",
    "print(dd)\n",
    "print(data[\"review_bert_input_ids\"].iloc[0])\n",
    "print(tokenizer.decode(data[\"review_bert_input_ids\"].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(a, b, c):\n",
    "   return a, b, c\n",
    "\n",
    "a, *b = foo(1, 2, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('inferno')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb978afd226374b4f3169fbe5928f76e34f2c89add9ee986f2aa663d426af832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
