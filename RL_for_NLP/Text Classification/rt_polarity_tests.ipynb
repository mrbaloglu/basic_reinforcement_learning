{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"/Users/emrebaloglu/Documents/RL/basic_reinforcement_learning\")\n",
    "from RL_for_NLP.text_environments import TextEnvClfBert, TextEnvClf\n",
    "from RL_for_NLP.text_data_pools import PartialReadingDataPoolWithWord2Vec, PartialReadingDataPoolWithBertTokens\n",
    "import NLP_utils.preprocessing as nlp_processing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/Users/emrebaloglu/Documents/RL/basic_reinforcement_learning/NLP_datasets/RT_Polarity',\n",
       " 'max_len': 50,\n",
       " 'vocab_size': 28996}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/Users/emrebaloglu/Documents/RL/basic_reinforcement_learning/NLP_datasets/RT_Polarity/data_info_bert.json\", \"r\") as f:\n",
    "    data_info = json.load(f)\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>label_str</th>\n",
       "      <th>review_bert_input_ids</th>\n",
       "      <th>review_bert_token_type_ids</th>\n",
       "      <th>review_bert_attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5829</td>\n",
       "      <td>1</td>\n",
       "      <td>does what fine documentary does best it extend...</td>\n",
       "      <td>good</td>\n",
       "      <td>[101, 1674, 1184, 2503, 4148, 1674, 1436, 1122...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3209</td>\n",
       "      <td>0</td>\n",
       "      <td>it drowns in sap</td>\n",
       "      <td>bad</td>\n",
       "      <td>[101, 1122, 22592, 1116, 1107, 21718, 1643, 10...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4323</td>\n",
       "      <td>0</td>\n",
       "      <td>the scriptwriters are no less menace to societ...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[101, 1103, 5444, 13814, 1116, 1132, 1185, 175...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>there an excellent minute film here unfortunat...</td>\n",
       "      <td>bad</td>\n",
       "      <td>[101, 1175, 1126, 6548, 2517, 1273, 1303, 1667...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>narratively trouble every day is plodding mess</td>\n",
       "      <td>bad</td>\n",
       "      <td>[101, 8195, 1193, 3819, 1451, 1285, 1110, 185,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label                                             review  \\\n",
       "0        5829      1  does what fine documentary does best it extend...   \n",
       "1        3209      0                                  it drowns in sap    \n",
       "2        4323      0  the scriptwriters are no less menace to societ...   \n",
       "3         281      0  there an excellent minute film here unfortunat...   \n",
       "4         100      0    narratively trouble every day is plodding mess    \n",
       "\n",
       "  label_str                              review_bert_input_ids  \\\n",
       "0      good  [101, 1674, 1184, 2503, 4148, 1674, 1436, 1122...   \n",
       "1       bad  [101, 1122, 22592, 1116, 1107, 21718, 1643, 10...   \n",
       "2       bad  [101, 1103, 5444, 13814, 1116, 1132, 1185, 175...   \n",
       "3       bad  [101, 1175, 1126, 6548, 2517, 1273, 1303, 1667...   \n",
       "4       bad  [101, 8195, 1193, 3819, 1451, 1285, 1110, 185,...   \n",
       "\n",
       "                          review_bert_token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                          review_bert_attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = nlp_processing.openDfFromPickle(data_info[\"path\"] + \"/rt-polarity-train-bert.pkl\")\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare some hyperparameters\n",
    "\n",
    "WINDOW_SIZE = 8\n",
    "MAX_STEPS = int(1e+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length in pool: 50\n",
      "Maximum sentence length in pool: 50\n",
      "Maximum sentence length in pool: 50\n"
     ]
    }
   ],
   "source": [
    "data_test = nlp_processing.openDfFromPickle(data_info[\"path\"] + \"/rt-polarity-test-bert.pkl\")\n",
    "data_val = nlp_processing.openDfFromPickle(data_info[\"path\"] + \"/rt-polarity-val-bert.pkl\")\n",
    "\n",
    "train_pool = PartialReadingDataPoolWithBertTokens(data_train, \"review\", \"label\", \"good\", WINDOW_SIZE)\n",
    "test_pool = PartialReadingDataPoolWithBertTokens(data_test, \"review\", \"label\", \"good\", WINDOW_SIZE)\n",
    "val_pool = PartialReadingDataPoolWithBertTokens(data_val, \"review\", \"label\", \"good\", WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_env = TextEnvClfBert(train_pool, MAX_STEPS)\n",
    "val_env = TextEnvClfBert(val_pool, 1000)\n",
    "test_env = TextEnvClfBert(test_pool, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertObservation(sample_str='does what fine documentary does best it extends warm invitation into an unfamiliar world then illuminates it fully and allows the larger implications of the journey to sink in unobtrusively ', sample_input_id_vecs=[array([ 101., 1674., 1184., 2503., 4148., 1674., 1436., 1122.]), array([ 8559.,  3258.,  8727.,  1154.,  1126., 17546.,  1362.,  1173.]), array([ 5178., 14088., 13978.,  1116.,  1122.,  3106.,  1105.,  3643.]), array([ 1103.,  2610., 14755.,  1104.,  1103.,  5012.,  1106.,  7496.]), array([ 1107.,  8362., 12809., 18062., 17849.,  1193.,   102.,     0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.])], sample_token_type_vecs=[array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.])], sample_attn_mask_vecs=[array([1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 1.]), array([1., 1., 1., 1., 1., 1., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0.])], label_str='good', label_enc=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_env.current_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import reinforce_algorithm_utils as rl_monte_carlo\n",
    "import gym\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n",
      "8 4\n"
     ]
    }
   ],
   "source": [
    "print(train_env.current_state_input_id.shape)\n",
    "s_size = train_env.current_state_input_id.shape[0]\n",
    "a_size = len(train_env.action_space)\n",
    "print(s_size, a_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"h_sizes\": [64, 32],\n",
    "    \"n_training_episodes\": 100000,\n",
    "    \"n_evaluation_episodes\": 10,\n",
    "    \"max_t\": 25,\n",
    "    \"gamma\": 1.0,\n",
    "    \"lr\": 1e-2,\n",
    "    \"env_id\": None,\n",
    "    \"state_space\": s_size,\n",
    "    \"action_space\": a_size,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create policy and place it to the device\n",
    "import policy_networks as pn\n",
    "\"\"\"policy = pn.Transformer_Baseline_Policy(data_info[\"vocab_size\"], hyperparameters[\"state_space\"], hyperparameters[\"action_space\"],\n",
    "                                        num_heads=1, num_layers=1)\"\"\"\n",
    "policy = pn.RNN_Baseline_Policy(data_info[\"vocab_size\"], hyperparameters[\"state_space\"], hyperparameters[\"action_space\"])\n",
    "optimizer = Adam(policy.parameters(), lr=hyperparameters[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': RNN_Baseline_Policy(\n",
      "  (embed_enc): Embedding(28996, 5, max_norm=True)\n",
      "  (rnn): GRU(5, 2, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=32, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      "), 'embed_enc': Embedding(28996, 5, max_norm=True), 'rnn': GRU(5, 2, num_layers=2, batch_first=True, bidirectional=True), 'flat': Flatten(start_dim=1, end_dim=-1), 'fc1': Linear(in_features=32, out_features=50, bias=True), 'fc2': Linear(in_features=50, out_features=50, bias=True), 'fc3': Linear(in_features=50, out_features=4, bias=True)}\n"
     ]
    }
   ],
   "source": [
    "params = dict(policy.named_modules())\n",
    "print(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import json\n",
    "\n",
    "params_s = str(params)\n",
    "mlflow.log_dict(params_s, \"params.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = rl_monte_carlo.reinforce_algorithm(train_env, policy,\n",
    "                   optimizer,\n",
    "                   hyperparameters[\"n_training_episodes\"], \n",
    "                   hyperparameters[\"max_t\"],\n",
    "                   hyperparameters[\"gamma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.8931568569324175"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1e-1*(np.log2(500000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_monte_carlo.evaluate_agent(train_env, 10, 100, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_monte_carlo.evaluate_agent(val_env, 10, 100, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_monte_carlo.evaluate_on_clf(val_env, policy, pos_label=\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, env):\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    total_reward = 0.0\n",
    "    actions = []\n",
    "    while not done:\n",
    "        action, _states = model.predict(obs)\n",
    "        action = action.item()\n",
    "        obs, rewards, done, info = env.step(action)\n",
    "        actions.append(env.action_space.ix_to_action(action))\n",
    "        total_reward += rewards\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(f\"Predicted Label {actions}\")\n",
    "    print(f\"Oracle Label: {env.current_label}\")\n",
    "    print(f\"Total Reward: {total_reward}\")\n",
    "    print(\"---------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(policy, val_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mlflow.set_tracking_uri(\"file:/Users/emrebaloglu/Documents/RL/basic_reinforcement_learning/agent_models/rt-polarity\")\n",
    "mlflow.set_experiment(\"rnn\")\n",
    "mlflow.start_run()\n",
    "mlflow.log_param(\"n_episodes\", 500)\n",
    "mlflow.pytorch.log_model(policy, \"rnn-default\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"file:/Users/emrebaloglu/Documents/RL/basic_reinforcement_learning/agent_models/rt-polarity\")\n",
    "uri = \"runs:/9f09e3fa6df6427ba2889e89ac787bcc/rnn-default\"\n",
    "\n",
    "model = mlflow.pytorch.load_model(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_monte_carlo.evaluate_agent(env, 10, 100, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_monte_carlo.evaluate_on_clf(env, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.dqn.policies import MlpPolicy\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "model = DQN(policy=MlpPolicy, env=train_env, learning_rate=0.001, batch_size=3)\n",
    "\n",
    "for i in range(int(5)):\n",
    "    model.learn(total_timesteps=int(1e+3), reset_num_timesteps=False)\n",
    "    eval_model(model, val_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the state space and action space\n",
    "s_size = train_env.observation_space.shape[0]\n",
    "a_size = len(train_env.action_space.actions)\n",
    "print(s_size, a_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C(policy = \"MlpPolicy\",\n",
    "            env = train_env,\n",
    "            gae_lambda = 0.9,\n",
    "            gamma = 0.99,\n",
    "            learning_rate = 0.00096,\n",
    "            max_grad_norm = 0.5,\n",
    "            n_steps = 8,\n",
    "            vf_coef = 0.4,\n",
    "            ent_coef = 0.0,\n",
    "            tensorboard_log = \"./tensorboard\",\n",
    "            policy_kwargs=dict(\n",
    "            log_std_init=-2, ortho_init=False),\n",
    "            normalize_advantage=False,\n",
    "            use_rms_prop= True,\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    model.learn(500, log_interval=250)\n",
    "    print(evaluate_policy(model, val_env, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, val_env, n_eval_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_monte_carlo.evaluate_on_clf(val_env, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('inferno')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb978afd226374b4f3169fbe5928f76e34f2c89add9ee986f2aa663d426af832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
